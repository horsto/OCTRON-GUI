# Main YOLO Octron class
# We are using YOLO11 as the base class for YOLO Octron.
# See also: https://docs.ultralytics.com/models/yolo11
import shutil
from pathlib import Path
from octron.yolo_octron.helpers.yolo_checks import check_yolo_models
from octron.yolo_octron.helpers.training import (
    collect_labels,
    collect_polygons,
    train_test_val,
    write_training_data,
    write_yolo_config_yaml
)

class YOLO_octron:
    """
    YOLO11 segmentation model class for training with OCTRON data.
    
    This class encapsulates the full pipeline for preparing annotation data from OCTRON,
    generating training datasets, and training YOLO11 models for segmentation tasks.
    """
    
    def __init__(self, 
                 project_path, 
                 models_yaml_path,
                 clean_training_dir=True
                 ):
        """
        Initialize YOLO_octron with project and model paths.
        
        Parameters
        ----------
        project_path : str or Path
            Path to the OCTRON project directory
        model_yaml_path : str or Path, optional
            Path to list of available (standard) YOLO models.
        clean_training_dir : bool, optional
            Whether to clean the training directory if it is not empty.
            
        """
        try:
            from ultralytics import settings
            self.yolo_settings = settings
        except ImportError:
            raise ImportError("YOLOv11 is required to run this class.")
        
        self.project_path = Path(project_path)
        if not self.project_path.exists():
            raise FileNotFoundError(f"Project path not found: {self.project_path}")
        
        self.models_yaml_path = Path(models_yaml_path) 
        if not self.models_yaml_path.exists():
            raise FileNotFoundError(f"Model YAML file not found: {self.models_yaml_path}")

        # Check YOLO models
        self.models_dict = check_yolo_models(YOLO_BASE_URL=None,
                                             models_yaml_path=self.models_yaml_path,
                                             force_download=False
                                             )

        # Setup folders for training
        self.training_path = self.project_path / 'model' # Path to all model output
        self.data_path = self.training_path / 'training_data' # Path to training data
        # Folder checks
        try:
            self.training_path.mkdir(exist_ok=False)
        except FileExistsError as e:
            # Check if training data folder is empty
            if len(list(self.training_path.glob('*'))) > 0:
                if not clean_training_dir:
                    raise FileExistsError(
                        f'"{self.training_path.as_posix()}" is not empty. Please remove subfolders first.'
                        )
                else:
                    shutil.rmtree(self.training_path)
                    self.training_path.mkdir()
                    print(f'Created fresh training directory "{self.training_path.as_posix()}"')
        
        # Initialize model to None (will be loaded when needed)
        self.model = None
        self.label_dict = None
        self.config_path = None
        
        print(f"YOLO Octron initialized with project: '{self.project_path.as_posix()}'")
    
    
    def prepare_labels(self, 
                       prune_empty_labels=True, 
                       min_num_frames=10, 
                       verbose=False, 
                       ):
        """ 
        Using collect_labels(), this function finds all object organizer 
        .json files from OCTRON and parses them to extract labels.
        """
        
        self.label_dict = collect_labels(self.project_path, 
                                         prune_empty_labels=prune_empty_labels, 
                                         min_num_frames=min_num_frames, 
                                         verbose=verbose
                                        )    
        if verbose: print(f"Found {len(self.label_dict)} organizer files")
    
    def prepare_polygons(self):
        """
        Using collect_polygons(), this function extracts polygons from the
        masks/labels generated by self.prepare_labels().
        """
        if self.label_dict is None:
            raise ValueError("No labels found. Please run prepare_labels() first.")
        
        self.label_dict = collect_polygons(self.label_dict) 
            
    
    def prepare_split(self,
                      training_fraction=0.7,
                      validation_fraction=0.15,
                      verbose=False,
                     ):
        """
        Using train_test_val(), this function splits the data into training,
        testing, and validation sets.   
        """
        if self.label_dict is None:
            raise ValueError("No labels found. Please run prepare_labels() first.")
        
        for labels in self.label_dict.values():
            for entry in labels:
                if entry == 'video':
                    continue    
                # label = labels[entry]['label']
                frames = labels[entry]['frames']   
                split_dict = train_test_val(frames, 
                                            training_fraction=training_fraction,
                                            validation_fraction=validation_fraction,
                                            verbose=verbose,
                                            )

                labels[entry]['frames_split'] = split_dict
        
    
    def create_training_data(self):
        """
        Using write_training_data(), this function writes the training data
        to the training_data directory.
        """
        if self.label_dict is None:
            raise ValueError("No labels found. Please run prepare_labels() first.")
        
        # Completeness checks
        for labels in self.label_dict.values(): 
            for entry in labels:
                if entry == 'video':
                    continue
                assert 'frames' in labels[entry], "No frame indices (frames) found in labels"
                assert 'polygons' in labels[entry], "No polygons found in labels, run prepare_polygons() first"
                assert 'frames_split' in labels[entry], "No data split found in labels, run prepare_split() first"  


        write_training_data(self.label_dict, self.data_path, verbose=True)
    
    
    
    def write_yolo_config(self,
                         train_path="train",
                         val_path="val",
                         test_path="test",
                        ):
        """
        Write the YOLO configuration file for training.
        
        Parameters
        ----------
        train_path : str
            Path to training data (subfolder of self.data_path)
        val_path : str
            Path to validation data (subfolder of self.data_path)
        test_path : str
            Path to test data (subfolder of self.data_path)
            
        """
        if self.label_dict is None:
            raise ValueError("No labels found.")
        
        dataset_path = self.data_path
        if len(list(dataset_path.glob('*'))) <= 1:
            raise FileNotFoundError(
                f"No training data found in {dataset_path.as_posix()}. Please run create_training_data() first."
                )
        if (not (dataset_path / "train").exists() 
            or not (dataset_path / "val").exists() 
            or not (dataset_path / "test").exists()
            ):
            raise FileNotFoundError(
                f"Training data not found(train/val/test). Please run create_training_data() first."
                )   
        
        # Get label names from the object organizer
        label_id_label_dict = {}
        for labels in self.label_dict.values():
            for entry in labels:
                if entry == 'video':
                    continue   
                if entry in label_id_label_dict:
                    assert label_id_label_dict[entry] == labels[entry]['label'],\
                        f"Label mismatch for {entry}: {label_id_label_dict[entry]} vs {labels[entry]['label']}"
                else:
                    label_id_label_dict[entry] = labels[entry]['label']

        # Write the YAML config
        self.config_path = self.data_path / "yolo_config.yaml"
        _ = write_yolo_config_yaml(
            output_path = self.config_path,
            dataset_path = dataset_path,
            train_path = train_path,
            val_path = val_path,
            test_path = test_path,
            label_dict = label_id_label_dict,
        )
        
    
    
    def load_model(self, model_name_path):
        """
        Load the YOLO model
        
        Parameters
        ----------
        model_name_path : str or Path
            Path to the model to load, or name of the model to load
            (e.g. 'YOLO11m-seg'), defaults to the model in the models.yaml file.
        
        Returns
        -------
        model : YOLO
            Loaded YOLO model
        """
         
        # Configure YOLO settings
        self.yolo_settings.update({
            'sync': False,
            'hub': False,
            'runs_dir': self.training_path.as_posix()
        })
        from ultralytics import YOLO   
        
        # Load specified model
        try:
            assert Path(model_name_path).exists()
            # If this path exists, load this model, otherwise 
            # assume that this models is part of the models_dict
        except AssertionError:
            model_name_path = self.models_dict[model_name_path]['model_path']
            model_name_path = self.models_yaml_path.parent / f'models/{model_name_path}'    
            
        self.model = YOLO(model_name_path)
        print(f"Model loaded from '{model_name_path.as_posix()}'")
        
        return self.model
    

    
    def train(self, 
              device='cpu',
              epochs=30, 
              ):
        """
        Train the YOLO model
        
        Parameters
        ----------
        device : str
            Device to use for training (i.e. "cpu", "mps" or "cuda")
            CAREFUL: There are still issues in pytorch for MPS,
            so it is recommended to use "cpu" for now.
        epochs : int
            Number of epochs to train for
      
        Returns
        -------
        results : dict
            Training results
        """
        if not self.model:
            print('ðŸ˜µ No model loaded!')
            return
            
        if self.config_path is None or not self.config_path.exists():
            raise FileNotFoundError(
                "No configuration .yaml file found."
            )
        if device not in ['cpu', 'cuda', 'mps']:
            raise ValueError(f"Invalid device: {device}")   
        if device == 'mps':
            print("âš  MPS is not yet fully supported in PyTorch. Use at your own risk.")
            
        # Setup callbacks
        self.num_epochs = epochs
        # Start training
        print(f"Starting training for {epochs} epochs...")
        results = self.model.train(
                      data=self.config_path, 
                      save_dir=self.training_path.as_posix(),
                      name='training',
                      mode='segment',
                      device=device,
                      mask_ratio=4,
                      epochs=self.num_epochs,
                      imgsz=640,
                      resume=False,
                      plots=True,
                      batch=.9,
                      cache=False,
                      save=True,
                      save_period=15,
                      project=None,
                      exist_ok=True,
                      # augmentation
                      augment=True,
                      hsv_v=.25,
                      degrees=180,
                      scale=.5,
                      shear=2,
                      flipud=.1,
                      fliplr=.1,
                      mosaic=1.0,
                      copy_paste=.5,
                      copy_paste_mode='mixup', 
                      erasing=.25,
                      crop_fraction=1.0,
                      )
        
        print("Training complete!")
        return results
    
    def validate(self, data=None, device='auto', plots=True):
        """
        Validate the model
        
        Parameters
        ----------
        data : str or Path, optional
            Path to validation data, defaults to the validation set in the config
        device : str
            Device to use for inference
        plots : bool
            Whether to generate plots
            
        Returns
        -------
        metrics : dict
            Validation metrics
        """
        # TODO: Which model to validate
        
        # if self.model is None:
        #     self.load_model()
            
        # data_path = data if data else self.config_path
        # print(f"Running validation on {data_path}...")
        
        # metrics = self.model.val(data=data_path, device=device, plots=plots)
        
        # print("Validation results:")
        # print(f"Mean Average Precision for boxes: {metrics.box.map}")
        # print(f"Mean Average Precision for masks: {metrics.seg.map}")
        
        return metrics
    
    def predict(self):
        # # Run inference on 'bus.jpg' with arguments
        # model.predict('/Users/horst/Downloads/octron_project/test data/8_behaviour_filtered2024-11-04T14_20_34_20240930_Th19.mp4', 
        #               save=True, 
        #               classes=[0],
        #               imgsz=1000, 
        #               device='cpu',
        #               visualize=False,
        #               conf=0.9
        #               )
        pass